# 工具复现项目文档

蒋睿兮 191250063 AI测试方向 

创建时间：2021.11.13 最后一次修改：2021.11.29



## 论文理解部分：

### 论文题目：Counterexample-Guided Data Augmentation

### 				   					反例引导式数据扩充/以反例为指导的数据扩增方法

### 论文的源码可在GitHub仓库：[dreossi/analyzeNN (github.com)](https://github.com/dreossi/analyzeNN)查看

### 论文中进行比较的经典数据扩增技术：imgaug，可在https://github.com/aleju/imgaug查看

### 论文中训练的模型：squezeDet，这是一种用于自动驾驶的CNN实时对象检测器。

### 文中提到的图片可在文件 图片汇总.word 中查看





### 论文要点：



论文的主要内容：扩增机器学习的反例数据集，反例是指分类错误示范的实例。用反例数据来重新训练和改进模型。

作者将所提出的框架与经典增强技术进行了比较，以展示该框架的有效性。结果显示反例增强集包含模型无法从经典

增强技术训练集中学习的信息。作者实现了三种工具，分别是：1. 图像生成器：渲染用于欺骗和重新训练 CNN 的合

成图片，图像生成器还提供有关错误分类图像的信息，例如元素的配置，亮度，对比度等。 2.采样器：从合成图片空

间采样配置。 3. 分析器：跟踪统计数据（例如，生成的图像、错误分类的特征、评估指标等） 。作者进行比较的对

象是基于深度神经网络的自动驾驶中目标检测的案例。因此使用的图像素材都是汽车、道路和环境图片，生成的数据

也都是和汽车行驶有关的图像。



论文的背景：目前的机器学习算法生成的模型在可信度上面存在问题。让模型精度更高则需要更多的数据，于是对于

机器学习来说，需要进行数据扩增来增加数据的数量。而目前的数据扩增主要包括改变图像几何形状的几何变换（例

如，旋转，缩放，裁剪或翻转）;和改变颜色通道的光度变换。但是这样的数据扩增只是提高了模型的准确性，而没有

考虑到模型学习到了什么样的新特征。而作者提出了一种新的数据增强方案，即反例引导的数据扩增。这种新方法并

不使用原来的数据集生成新的数据，而是使用新的错误分类来进行数据扩增。增强方案取决于生成错误分类图像的能

力，因此作者开发了一个图像生成器，与采样器共同生成新的图像。



论文的主要贡献：•  一种反例引导的数据扩充方法，其中只有错误分类的示例被迭代地添加到训练集中；

​							 	•  一个合成图像生成器，可以生成真实的反例；

​								 •  错误表存储有关反例的信息，它的分析提供了解释，促进生成反例图像。



论文中数据扩增的基本方法：1）生成被模型错误分类的合成图像，即反例;

​													  2）将反例添加到训练集中;

​													  3） 在增强数据集上训练模型。


论文中提到的方法的基本流程：以一个修改空间M作为输入，M是图像生成器可能的配置空间。空间M是有意义的而

不是随机生成的，空间中的每一个修改在模型的应用域中都有意义，这能确保扩增的数据都是有意义的。M输入之

后，采样器从M中选择一个修改项m，样本m是由采样方法确定的。然后图像生成器使用这个修改项m生成图片x。图

像x则作为所要训练的模型f的输入，模型f判断x是不是反例数据，如果是反例，则将x添加到增强集A中去，并且将x

的信息更新到错误表中。如此循环，直到增强集A已经足够大或者修改空间已经被有效地覆盖。生成的增强集A就可

以用来训练模型f了。（基本流程见图1）





论文的总体结构：第一节是总体介绍，介绍了一些论文的大体背景和思路；第2节引入了一些符号;第3节描述了用于

渲染合成图像的图像生成器;第4节介绍了一些采样技术，可用于有效地对修改空间进行采样;第5节介绍了错误表，并

详细介绍了如何使用它们来提供关于反例的例证;第6节通过评估所提出的技术并比较反例引导的扩增方案和针对经典

增强的不同调整方法;第7节则是对整个论文进行了总结。





论文第二节：预备知识。本节介绍了论文用到的表示方法。





论文第三节：图像生成器。整个论文的核心就是图像生成器。

图像生成器实现的是生成函数γ：M → X，它会将一个修改生成为一幅图像。论文中的图像生成器是在14个维度上生

成一副独特的图像。这14个维度包括许多方面的特征，例如汽车的数量以及汽车在道路上的位置（离路边的距离和离

拍摄地点的位置，分别用x和z表示），还有图片的亮度，清晰度，对比度和颜色等重要特征（生成的图像例子见图

2）。



当然，能够生成大数量的图片，就需要有一种方法来衡量不同图片之间的差异程度。论文中定义了一个变量来表证图

像间的差异。设 m（1）、m（2） ∈ M 为修饰。具体的定义见公式1。其中 1 条件为 1（如果条件为真），否则为 

0，以及|| · || 是 L2 规范。距离计算了补间背景和汽车模型的差异，并添加了对应于 x 和 z 位置、亮度、锐度、对

比度和图像颜色的点的欧氏距离。作者计算了图2中三个例子的差异值来显示它们之间的差异程度。定义这个变量对

于保证图片的多样性非常重要。



论文中使用了一个附带的用作基本图像的地面和汽车模型数据库。数据库由 35 个道路场景（例如，沙漠、森林或高

速公路场景）和 36 个车型（例如，经济型、家庭型或跑车，从前视图和后视图）组成。数据库可以很容易地扩展或

被用户替换。



最后一个问题是图片生成器如何正确地放置汽车。这涉及到前文提到过的x和z两个维度，图像生成器将数据库中的道

路有关的图像进行分析，对于特定道路，程序会绘制一个梯形，指定允许图像发生器放置汽车的区域。程序还指定梯

形底座上汽车图像的比例，即在距离观察者最远和最远的点处（见图3）。此外，图像生成器根据图像的视角叠加不

同的车辆。图像生成器还会执行多项检查，以确保渲染的汽车可见。



论文第四节：采样方法。采样器的目的是实现对于样本空间M的良好覆盖。论文一共有三种采样的方法。

•  统一随机抽样：统一随机抽样可确保从M中抽样任何可能点的概率相等，从而保证了用于训练和测试的良好生成图

像组合。这是一种简单有效的技术，既适用于训练，也可用于测试，但它可能无法很好地覆盖修改空间;

•  低差异采样：低差异（或准随机）序列是 n 元组序列，它比不相关的随机点更均匀地填充 nD 空间。低差异序列有

助于通过减少间隙和点聚类来覆盖盒子，从而确保样品空间的均匀覆盖。通俗地理解低差异采样就是人为地影响采

样，使得采样在整个空间中呈现出均分布的情况。论文中使用的是Halton序列的低差异采样，它能够保证采样在n维

空间均匀分布，适合对于论文中用到的14维度样本空间进行采样。统一随机抽样和低差异采样的直观区别见图4。

•  交叉熵采样：交叉熵方法被开发为组合优化和重要性采样的通用蒙特卡罗方法。它是一种迭代采样技术，我们从给

定的概率分布中采样，并通过最小化交叉熵来更新分布。这种方法有些复杂，我不是很清楚它的大体流程，但是总结

下来它的目的是尽量使采样分布（撒的点）与实际情况同分布。

论文的实验过程中大体上就是使用这三种采样方法，不过在实际使用的时候会有一些改变，比如保证第三节中提到的

图片差异变量大于一定的值以保证样本空间被充分覆盖。





论文第五节：错误表。错误表是论文中提出的一个重要的新的数据结构，它能够帮助提供反例的说明，也能够用来生

成新的反例。本质上其实就是记录了许多图片特征的表。在第一种情况下，通过在反例中找到共同模式，程序向用户

提供反馈，例如"该模型没有检测到在森林道路上驶离我们的白色汽车";在第二种情况下，程序可以将采样器偏向于更

有可能导致反例的修改。

错误表的示例：见表一，简要描述就是一张表格，每一行代表一张反例图像，而各表头就是14个维度的数据，示例中

仅有六种特征，实际情况中会有更详细的数据。

错误表的功能：前文已经提到过，错误表可以存储反例的数据，也能够用来生成新的反例。除此之外，错误表还能对

不同的特征进行分类：

1.显式与隐式特征：显式特征是从修改空间（例如，x，z位置，亮度，对比度等）中采样的，

而隐式特征是用户提供的生成图像的各个方面（例如，汽车模型，背景场景等）。

2.有序与无序特征：某些特征具有具有明确定义的总排序（例如，清晰度）的域，而其他特征则没有排序的概念（例

如，汽车型号，背景场景的标识符等）。


隐式和显式功能集是互斥的。通常，隐式特征更具描述性，并表征生成的图像。这些对于提供反馈以解释分类器的漏

洞非常有用。虽然隐式特征是无序的，但显式特征可以是有序的，也可以是无序的。错误表行是用于错误分类的特征

的实现。错误表行是用于错误分类的特征的实现。


将特征分类之后，就需要对特征进行分析，对于有序特征和无序特征的分析是不同的。论文中使用奇异向量来查找模

型相对于有序特征的敏感程度。如果向量中与特征对应的值较小，则意味着模型对该特征的变化不可靠，即该特征的

变化会影响错误分类。或者，对应于奇异向量中较大值的特征充当"不关心"，即通过修复所有其他特征，模型无论该

特征的值如何，都会对图像进行错误分类;而对于无序特征来说，这一类特征是不能量化的，它们的值并不是需要关心

的东西，需要关心的就是哪些无序特征一起出现会影响到模型的判断。论文给出的应对方法是探索无序特征的所有可

能子集。论文提到，通过分析不同的特征，模型对于x位置、亮度、对比度的变化并不可靠，对于无序特征，论文提

出"该模型没有检测到在森林道路上驶离我们的白色汽车"。


分析完特征之后，就是考虑如何使用得到的信息进行采样了。注意只能从显式功能中进行采样。来自有序特征的反

馈：有序特征是显式特征的子集，已经告诉我们在采样过程中哪些特征需要更多变化。例如，在 5.2节 的示例中，我

们的采样器必须优先对第一辆车的不同 x 位置进行采样，然后是亮度，最后是其他有序特征之间的对比度;来自无序特

征的反馈：可以使用图像生成器库和错误表来识别库中哪些元素的组件对应于要素值，并相应地设置要素值。例如，

在 5.2节的示例中，对无序显式特征的分析表明，桥梁道路与特斯拉、梅赛德斯和马自达的组合最常被错误分类。使

用这些信息通过改变亮度和对比度来生成更多具有这种特定组合的图像。



论文第六节：实验评估。这节内容展示了作者是如何进行实际操作的。本节将展示如何使用所提出的技术来增强训练

集并提高所考虑模型的准确性。

注意事项：原始训练和测试集 X 和 T 分别包含图像生成器随机生成的 1500 张和 750 张图片。

​					分析所用的模型是squezeDet，这是一种用于自动驾驶的CNN实时对象检测器。

​					所有模型都经过了65个迭代的训练。



6.1：各种扩增方法的比较，实验的结果见表2

表2中不同的表头代表的是不同的采样方法生成的训练集。在这个表中，R对应均匀随机，H对应Halton低差异序列，

C对应交叉熵，D对应具有距离约束的均匀随机（采用第3.1节中的距离，要求反例的修改必须彼此之间至少相距

0.5），M则是包含由所有 R、H、C、D 采样方法生成的反例的相等组合。而不同行代表的是在不同训练集上训练的

模型。第一行是不经过扩增的原始训练集训练的模型；第二行是使用经典的数据扩增项目imgaug1扩增之后的训练集

训练的模型；后面几行就是对应论文中不同采样方法生成的训练集训练的模型。简而言之就是用不同的采样方法生成

的测试集来测试不同的方法生成的训练集训练的模型。最终得到的结果就是平均精度（上）和召回率（下）。

对于每种采样方法，论文中生成 了1500 个反例，其中一半注入到原始训练中集合 X 而另一半用作测试集。经过实

验，得到了以下的结论：首先，与经典的增强方法相比，使用反例引导增强方法的原始模型的准确性提高更大。其

次，在所提出的技术中，交叉熵在精度方面具有最高的改进，但低差异性方法在精度和召回率方面往往比其他方法平

均表现更好（其实我对于这一段有疑问，论文中的数据和表中的数据不一样，我不是很清楚其中的计算关系）。论文

中还提到，最大化增强集的多样性（以及随后的准确性提高）需要更多的迭代。




6.2：循环增强，验证模型是不是会过度地拟合生成的反例数据。

这个实验仅考虑统一随机抽样方法，并在多个增强循环中增量扩充训练集。这个实验的目的是了解模型是否过度拟合

反例，看看是否有可能达到饱和点，即无法生成反例的模型。结果显示，经过多次增强训练的模型生成反例变得越来

越困难。反例生成的计算难度随着周期数的增加，是机器学习模型中增加保证的非正式经验衡量标准。对于每个周

期，扩增功能都会提高模型相对于测试集的准确性。更有趣的是，原始测试集上的模型精度不会降低，而是实际上会

随着时间的推移而提高（至少对于所选的增强比率）。

以我的理解，这说明模型不会过度地拟合生成的反例数据。



6.3：误差表引导采样，最后一个实验评估，使用误差表来分析通过均匀随机抽样为由原始训练集训练的模型生成的反

例。实验分析了有序和无序特征，结果显示模型对图像变化比对其元素的配置更敏感。对无序特征的出现次数统计显

示，错误分类中出现次数最多的前三名车型是白色保时捷，黄色Corvette和浅绿色菲亚特。有趣的是，与流行的汽车

相比，所有这些车型都有不寻常的设计。最常出现的前三个背景场景是森林中的一座狭窄的桥梁，一个室内停车场和

一个市中心的城市环境。



论文第七节：论文的总结。总结中强调了误差表这一新型数据结构的重要性，提到了论文中的方法可以被视为反例引

导归纳合成（CEGIS）的一个实例，并且想象了论文中的技术应用于现实中的效果。



我对于论文的总结：这篇论文的思路比较新颖，不同于一般论文对机器学习算法本身进行改良的思路，它是从改进训练集方面入手的。它提出了以反例为引导的数据扩增方法。论文的作者注意到传统的数据扩增技术只是单纯地进行数据扩增，而没有考虑过扩增的数据能够给模型带来什么新的东西。于是论文中设计了一种新的训练、测试、扩增方式，首先是用随机的数据训练和测试模型，然后收集测试中模型错误识别的数据，根据这些数据生成出大批量的新的数据，进而用这些模型识别错误的数据类型来进一步训练模型，如此循环。论文中有三个重要的工具，分别是图像生成器、采样器、分析器，同时还提出了一种新的数据结构：错误表用来收集反例的各种特征。论文介绍了三种工具和错误表的大体情况，并且介绍了使用这些工具进行机器学习模型训练的结果并与传统的方法进行了比较。论文中的结果充分证明以反例为引导进行数据扩增这一思路比传统方法具有优势。虽然论文具有一定的局限性（如只在squezeDet这一模型上进行了测试，比较的传统方法也只有imgaug这一钟传统数据扩增方法），但是论文中的测试结果是可以复现和通用的，论文中的技术应用到现在的生产中应该能有用武之地。最重要的是，论文中的思想，这种用模型判断错误的数据来大规模训练模型的思想值得我们深思。





## 代码理解部分

### 源码简介：

源码发布在GitHub上，项目名称叫analyzeNN，是一个一个用于分析和改进用于自动驾驶的 CNN 的平台。分为三部分，分别是需要用到的图片数据库、squeezeDet项目代码以及作者自己实现的若干个py文件。

### 代码整体结构：

图像生成器：渲染用于欺骗和重新训练 CNN 的合成图片 

采样器：从合成图片空间采样配置 

分析器：跟踪统计数据（例如，生成的图像、错误分类的特征、评估指标等） 

工具 用于移动对象并存储修改的 GUI 从存储的修改生成图像 数据集：更多弯曲的道路，前车 不止一辆车 

训练 了解原始/合成图像的比例 概括 比较抽样方法 比较目标抽样与随机抽样 CPS 模型中的重新训练模块 

### 我在分析代码时遇到的问题：

论文中给出的源码相当混乱，没有写注释，各个py文件也没有分类，说明文档也是笼统的几句话，不知道各个文件的运行先后顺序，也不知道有哪些库是需要自建的。在摸索了一周之后我还是没有找到完美的解决办法。几个具体的问题可在 源码分析.word 文档查看。



### 我对于代码的理解：

很惭愧，我并没有能够理解全部代码，我只能从整体上分析每个文件的大致作用。在理解源码的一周中，我也查阅了许多资料，但是最终还是没能得到论文中的结果。我对于代码的一些理解可以在 源码分析.word 文档查看。



## 后记

我从11月13日开始着手完成自动化测试工具复现作业。在艰难地理解了一周论文内容之后，我找到了论文的源码，试图运行源码来帮助自己进一步理解论文的思路。可是我发现，以我的编程水平连理解代码的基本结构都成问题，我在环境配置、python包导入等基础步骤上都遇到了很多我自己无法克服的困难。经过了一周的对于源码的阅读后，我依然无法运行源码，这个时候我其实已经对于完成整个工具复现不抱希望了。这次工具复现作业占用了我大部分的空闲时间，但我还是没有办法完成任务，我对于自己的水平和理解水平感到非常难过，很抱歉不能完成这门课程的任务。但是事已至此，我只能尽自己最大的努力来尽可能地理解论文和论文中的工具。我最终提交的文档大部分都是我对于论文的理解，许多理解可能会很粗糙，但这些都是我通读不下10次论文，查阅了很多资料才堪堪写出的文字，这些关于论文的理解就是我在这次工具复现作业中仅有的成果了。很抱歉没能完成本次作业，虽然说不上历经千辛万苦，但这些也都是我花了不少时间才得到的，当意识到自己无法完成任务、写下这行文字时，我的内心十分痛苦。无论如何，请老师和助教能够看到我这些仅有的成果，很感谢老师和助教在这门课程上给我的帮助！

​																																										蒋睿兮 2021.11.29





















